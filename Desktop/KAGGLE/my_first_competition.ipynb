{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. Loading packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno\n\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Loading dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Data Exploration and Preparation"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"train data consist of {} rows and {} columns\".format(train.shape[0],train.shape[1]))\nprint(\"test data consist of {} rows and {} columns\".format(test.shape[0],test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.1 Univariate analysis"},{"metadata":{},"cell_type":"markdown","source":"3.1.1 Descriptive statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The plotted distribution of means for the **train** set"},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = train.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\nsns.distplot(train[variables].mean(axis=0),\n             color=\"magenta\",\n             kde=True,\n             bins=80, \n             label='train')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe plotted distribution of minimum and maximum values"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\n\nsns.distplot(train[variables].min(axis=0),\n             color=\"r\",\n             kde=True,\n             bins=80, \n             label='minimum').set_title(\"Plotted distribution of maximum and minimum values on train set\")\n\nsns.distplot(train[variables].max(axis=0),\n             color=\"g\",\n             kde=True,\n             bins=80, \n             label='maximum')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The plotted distribution of means for the **test** set"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\nsns.distplot(test[variables].mean(axis=0),\n             color=\"purple\",\n             kde=True,\n             bins=80, \n             label='train')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\n\nsns.distplot(test[variables].min(axis=0),\n             color=\"orange\",\n             kde=True,\n             bins=80, \n             label='minimum').set_title(\"Plotted distribution of maximum and minimum values on the test set\")\n\nsns.distplot(test[variables].max(axis=0),\n             color=\"violet\",\n             kde=True,\n             bins=80, \n             label='maximum')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparison of the train and test datasets"},{"metadata":{},"cell_type":"markdown","source":"* means"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\n\nsns.distplot(train[variables].mean(axis=0),\n             color=\"magenta\",\n             kde=True,\n             bins=80, \n             label='train').set_title(\"Plotted distribution of mean values for test and train sets\")\n\nsns.distplot(test[variables].mean(axis=0),\n             color=\"purple\",\n             kde=True,\n             bins=80, \n             label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Minimum values"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\n\nsns.distplot(train[variables].min(axis=0),\n             color=\"r\",\n             kde=True,\n             bins=80, \n             label='train').set_title(\"Plotted distribution of minimum values for test and train sets\")\n\nsns.distplot(test[variables].min(axis=0),\n             color=\"orange\",\n             kde=True,\n             bins=80, \n             label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Maximum values"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\n\nsns.distplot(train[variables].max(axis=0),\n             color=\"g\",\n             kde=True,\n             bins=80, \n             label='train').set_title(\"Plotted distribution of maximum values for test and train sets\")\n\nsns.distplot(test[variables].max(axis=0),\n             color=\"violet\",\n             kde=True,\n             bins=80, \n             label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Standart deviations"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set(style=\"darkgrid\")\n\nsns.distplot(train[variables].std(axis=0),\n             color=\"#808000\",\n             kde=True,\n             bins=80, \n             label='train').set_title(\"Plotted distribution of standart deviations for test and train sets\")\n\nsns.distplot(test[variables].std(axis=0),\n             color=\"#CD5C5C\",\n             kde=True,\n             bins=80, \n             label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(train.iloc[:,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Figure parameters\nplt.rcParams['figure.figsize'] = (8, 6)\ntitle_config = {'fontsize': 20, 'y': 1.05}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['target'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of 1 is less than 1/7 of distribution of 0."},{"metadata":{},"cell_type":"markdown","source":"3.2 Bivariate analysis"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\ncorrelation = train.corr()\nsns.heatmap(correlation,cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.3 Check for missing values "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nmissingno.matrix(train, figsize = (18,7))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: It looks like the both datasets have no missing values!"},{"metadata":{},"cell_type":"markdown","source":"4. Model selection"},{"metadata":{},"cell_type":"markdown","source":"* Variables declaration"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[variables]\ny_train = train[\"target\"]\n\nX_test = test[variables]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import cross_val_score\n\ndef fit_ml_algo(algo, X_train, y_train, X_test, cv):\n    \n        \n    pipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), algo)\n    model = pipeline.fit(X_train, y_train)\n    \n    fpr, tpr, thr = roc_curve(y_train, pipeline.predict_proba(X_train)[:,1])\n\n    \n    #model = algo.fit(X_train, y_train)\n    acc = round(model.score(X_train, y_train) * 100, 2)\n    \n    auc_score = auc(fpr, tpr)\n\n    auc_score_cv = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=10).mean()\n    \n  \n    return acc, auc_score,auc_score_cv, fpr, tpr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nacc_log, auc_log, auc_log_cv, fpr_log, tpr_log  = fit_ml_algo(LogisticRegression(penalty=\"l2\"), \n                                                                              X_train,\n                                                                              y_train,\n                                                                              X_test,\n                                                                              cv=10)\n\n\nprint(\"Accuracy: {}\".format(acc_log))\nprint(\"AUC score: {}\".format(auc_log))\nprint(\"AUC score CV 10-Fold: {}\".format(auc_log_cv))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gaussian Naive Bayes"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nacc_gaussian, auc_gaussian,auc_gaussian_cv, fpr_gaussian, tpr_gaussian = fit_ml_algo(GaussianNB(),\n                                                                     X_train,\n                                                                     y_train,\n                                                                     X_test,\n                                                                     10)\n\nprint(\"Accuracy: {}\".format(acc_gaussian))\nprint(\"AUC score: {}\".format(auc_gaussian))\nprint(\"AUC CV 10-Fold: {}\".format(auc_gaussian_cv))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nacc_knn, auc_knn, auc_knn_cv, fpr_knn, tpr_knn  = fit_ml_algo(KNeighborsClassifier(),\n                                                              X_train,\n                                                              y_train,\n                                                              X_test,\n                                                              cv=10)\n\n\nprint(\"Accuracy: {}\".format(acc_knn))\nprint(\"AUC score: {}\".format(auc_knn))\nprint(\"AUC score CV 10-Fold: {}\".format(auc_knn_cv))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Classfier"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.tree import DecisionTreeClassifier\n\nacc_dt, auc_dt, auc_dt_cv, fpr_dt, tpr_dt  = fit_ml_algo(DecisionTreeClassifier(),\n                                                              X_train,\n                                                              y_train,\n                                                              X_test,\n                                                              cv=10)\n\n\nprint(\"Accuracy: {}\".format(acc_dt))\nprint(\"AUC score: {}\".format(auc_dt))\nprint(\"AUC score CV 10-Fold: {}\".format(auc_dt_cv))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic Plot for Selected Models')\nplt.plot(fpr_log, tpr_log, label = \"Logistic regression\")\nplt.plot(fpr_gaussian, tpr_gaussian, label= \"Gaussian NB\")\nplt.plot(fpr_dt, tpr_dt, label= \"Tree Classifier\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature creation"},{"metadata":{},"cell_type":"markdown","source":"1) data augmentation"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def augment(x,y,t=5):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_tr, y_tr = augment(X_train.values, y_train.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr = pd.DataFrame(X_tr)\ny_tr = pd.DataFrame(y_tr)\nX_tr.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Gaussian Naive Bayes with data augmentation"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"%%time\ntrain_pred_gaussian, acc_gaussian, acc_cv_gaussian, auc_gaussian = fit_ml_algo(GaussianNB(), \n                                                                      X_tr, \n                                                                      y_tr,\n                                                                      X_test,   \n                                                                           10)\n\nprint(\"Accuracy: {}\".format(acc_gaussian))\nprint(\"Accuracy CV 10-Fold: {}\".format(acc_cv_gaussian))\nprint(\"AUC score: {}\".format(auc_gaussian))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Logistics Regression with augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_pred_log, acc_log, acc_cv_log, auc_log  = fit_ml_algo(LogisticRegression(penalty=\"l2\"), \n                                                  X_train_new, \n                                                  y_train_new,\n                                                  X_test,\n                                                  cv=10)\nprint(\"Accuracy: {}\".format(acc_log))\nprint(\"Accuracy CV 10-Fold: {}\".format(acc_cv_log))\nprint(\"AUC score: {}\".format(auc_log))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2) Feature creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nidx = features = train.columns.values[2:202]\nfor df in [test, train]:\n    df['sum'] = df[idx].sum(axis=1)  \n    df['min'] = df[idx].min(axis=1)\n    df['max'] = df[idx].max(axis=1)\n    df['mean'] = df[idx].mean(axis=1)\n    df['std'] = df[idx].std(axis=1)\n    df['skew'] = df[idx].skew(axis=1)\n    df['kurt'] = df[idx].kurtosis(axis=1)\n    df['med'] = df[idx].median(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# declare new dataset\nvariables = train.columns[2:]\nX_train_nf = train[variables]\n# expand dataset\nX_tr, y_tr = feature_creation(X_train_nf.values, y_train.values)\nX_tr = pd.DataFrame(X_tr)\ny_tr = pd.DataFrame(y_tr)\nX_tr.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_pred_gaussian, acc_gaussian, acc_cv_gaussian, auc_gaussian = fit_ml_algo(GaussianNB(), \n                                                                      X_tr, \n                                                                      y_tr,\n                                                                      X_test,   \n                                                                           10)\n\nprint(\"Accuracy: {}\".format(acc_gaussian))\nprint(\"Accuracy CV 10-Fold: {}\".format(acc_cv_gaussian))\nprint(\"AUC score: {}\".format(auc_gaussian))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy scores"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Decision Tree', \n              'Logistic Regression', \n              'Naive Bayes'\n             ],\n    'Score': [\n        acc_dt, \n        acc_log,  \n        acc_gaussian,\n    ],\n    'AUC_CV': [\n        auc_dt_cv,\n        auc_log_cv,\n        auc_gaussian_cv,\n    ]})\nprint(\"---Reuglar Accuracy Scores---\")\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Light GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.335,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.041,\n    'learning_rate': 0.0083,\n    'max_depth': -1,\n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': -1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_folds = 12\n\nfolds = StratifiedKFold(n_splits=num_folds, shuffle=False, random_state=2319)\noof = np.zeros(len(train))\ngetVal = np.zeros(len(train))\npredictions = np.zeros(len(y_train))\n\nprint('Light GBM Model')\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, y_train.values)):\n    print(\"Fold idx:{}\".format(fold_ + 1))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=y_train.iloc[trn_idx])\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=y_train.iloc[val_idx])\n    \n    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(y_train, oof)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature creation"},{"metadata":{},"cell_type":"markdown","source":"* Light GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}